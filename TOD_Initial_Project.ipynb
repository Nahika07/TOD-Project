{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nahika07/TOD-Project/blob/main/TOD_Initial_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMUKd8MEyQj0"
      },
      "outputs": [],
      "source": [
        "im#First goals, gather info\n",
        "#--find/assess data sets that include trainstations within PBC (Lightrail/Rail) Main: Tri-Rail/Brightline, + possibility of extracting data from google maps\n",
        "#--gather information within 5 mile radius within stations - (GeoPandas, GIS) *export info through excel file\n",
        "#**** See if there are any bus stations that are interconnected to train stations\n",
        "#****Comment for links\n",
        "#Second goals, automating information into dataframes/working on them (continue with Geopandas)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to local business data scraper: https://www.estrattoredati.com/local-business-extractor.html\n",
        "\n",
        "or the cheapest way would be to use the \"beautifusoup\" or the Scrap-It.Cloud (web scraping) library by first extracting the location and number of train stations in palm beach county.\n",
        "\n",
        "Still looking into it, might just need to use the Google maps API since BeautifulSoup doesnt seem to work with dynamic webpages (05/07)"
      ],
      "metadata": {
        "id": "FU6VGx_q5oW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install  bs4\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNwyldvLwlfQ",
        "outputId": "ec896b81-8b00-47f6-84ab-822f92a57181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# url = \"https://www.google.com/maps/search/train+stations+in+Palm+Beach+County,+FL/@26.6828687,-80.198439,11z/data=!3m1!4b1?entry=ttu\"\n",
        "# response = requests.get(url)\n",
        "# html_data = response.text\n",
        "\n",
        "# soup = BeautifulSoup(html_data, \"html.parser\")\n",
        "# train_stat = soup.find_all(\"div\", class_ = \"section-result-details-container\")\n",
        "\n",
        "# for train_stat in train_stat:\n",
        "#   name = train_stat.find(\"h3\", class_ = \"section-result-title\").text.strip()\n",
        "#   address = train_stat.find(\"span\", class_=\"section-result-location\").text.strip()\n",
        "\n",
        "#   print(\"Name:\", name)\n",
        "#   print(\"Address:\", address)\n",
        "#   print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "kfkQjOPty5qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omm7XGLN5wAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}